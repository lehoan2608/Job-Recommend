{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë User ID m·ªõi c·ªßa b·∫°n: c3706428\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "def get_user_id():\n",
    "    user_id_file = \"user_ids.txt\"  # File ƒë·ªÉ l∆∞u nhi·ªÅu user_id\n",
    "    \n",
    "    # T·∫°o user_id m·ªõi\n",
    "    new_user_id = str(uuid.uuid4())[:8]  # L·∫•y 8 k√Ω t·ª± ƒë·∫ßu c·ªßa UUID\n",
    "    \n",
    "    # L∆∞u user_id m·ªõi v√†o file\n",
    "    with open(user_id_file, \"a\") as f:  # M·ªü file ·ªü ch·∫ø ƒë·ªô append (th√™m v√†o cu·ªëi)\n",
    "        f.write(new_user_id + \"\\n\")  # Ghi user_id m·ªõi v√† xu·ªëng d√≤ng\n",
    "    \n",
    "    return new_user_id\n",
    "\n",
    "# L·∫•y user_id m·ªõi\n",
    "user_id = get_user_id()\n",
    "print(f\"üîë User ID m·ªõi c·ªßa b·∫°n: {user_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_skills = pd.read_csv('C:/HocTap/DoAnTotNghiep/archive/job_skills.csv')\n",
    "job_summary = pd.read_csv('C:/HocTap/DoAnTotNghiep/archive/job_summary.csv')\n",
    "job_posts = pd.read_csv('C:/HocTap/DoAnTotNghiep/archive/linkedin_job_postings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = job_posts.merge(job_summary, on=\"job_link\", how=\"left\").merge(job_skills, on=\"job_link\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['company', 'job_location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o job profile b·∫±ng c√°ch k·∫øt h·ª£p c√°c c·ªôt quan tr·ªçng\n",
    "df[\"job_profile\"] = df[\"job_title\"] + \" \" + df[\"job_summary\"] + \" \" + df[\"job_skills\"] + \" \" + df[\"job_level\"] + \" \" + df[\"job_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Account Executive - Dispensing (NorCal/Norther...\n",
      "1    Registered Nurse - RN Care Manager Employment ...\n",
      "2    RESTAURANT SUPERVISOR - THE FORKLIFT Job Detai...\n",
      "3    Independent Real Estate Agent Who We Are\\nRand...\n",
      "4                                                  NaN\n",
      "Name: job_profile, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"job_profile\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54156\n"
     ]
    }
   ],
   "source": [
    "print(df[\"job_profile\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë gi√° tr·ªã trong c·ªôt job_profile: 1294268\n"
     ]
    }
   ],
   "source": [
    "print(\"T·ªïng s·ªë gi√° tr·ªã trong c·ªôt job_profile:\", df[\"job_profile\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng gi√° tr·ªã NaN trong t·ª´ng c·ªôt:\n",
      "job_title          0\n",
      "job_summary    51120\n",
      "job_skills     54156\n",
      "job_level          0\n",
      "job_type           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"S·ªë l∆∞·ª£ng gi√° tr·ªã NaN trong t·ª´ng c·ªôt:\")\n",
    "print(df[[\"job_title\", \"job_summary\", \"job_skills\", \"job_level\", \"job_type\"]].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"job_profile\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y danh s√°ch k·ªπ nƒÉng, c·∫•p b·∫≠c, v·ªã tr√≠ h·ª£p l·ªá\n",
    "valid_skills = set(df[\"job_skills\"].str.split(\",\").explode().str.strip().dropna().unique())\n",
    "valid_levels = set(df[\"job_level\"].dropna().unique())\n",
    "valid_locations = set(df[\"job_location\"].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorization ho√†n t·∫•t.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "job_vectors = vectorizer.fit_transform(df[\"job_profile\"])\n",
    "\n",
    "print(\"TF-IDF vectorization ho√†n t·∫•t.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√¥ng vi·ªác ƒë∆∞·ª£c g·ª£i √Ω:\n",
      "                                                  job_link  \\\n",
      "740787   https://www.linkedin.com/jobs/view/nurse-pract...   \n",
      "244230   https://www.linkedin.com/jobs/view/business-an...   \n",
      "804488   https://www.linkedin.com/jobs/view/us-operatio...   \n",
      "1147830  https://www.linkedin.com/jobs/view/veterinaria...   \n",
      "576801   https://www.linkedin.com/jobs/view/data-qualit...   \n",
      "\n",
      "                                                 job_title  \\\n",
      "740787   Nurse Practitioner PRN- positions available st...   \n",
      "244230                                Business Analyst III   \n",
      "804488   US Operational Health, Safety, Security & Envi...   \n",
      "1147830  Veterinarian - Mentorship, Training, and Auton...   \n",
      "576801                       Data Quality Business Analyst   \n",
      "\n",
      "                                        company  \\\n",
      "740787   Northeast Healthcare Recruitment, Inc.   \n",
      "244230               Oloop Technology Solutions   \n",
      "804488                           Energy Jobline   \n",
      "1147830                       The VET Recruiter   \n",
      "576801           New York eHealth Collaborative   \n",
      "\n",
      "                            job_location  \n",
      "740787                        Albany, NY  \n",
      "244230                      New York, NY  \n",
      "804488                      New York, NY  \n",
      "1147830                     New York, NY  \n",
      "576801   New York City Metropolitan Area  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "candidate_skills = input(\"Nh·∫≠p k·ªπ nƒÉng c·ªßa b·∫°n: \")\n",
    "candidate_level = input(\"Nh·∫≠p c·∫•p b·∫≠c mong mu·ªën: \")\n",
    "candidate_location = input(\"Nh·∫≠p v·ªã tr√≠ mong mu·ªën: \")\n",
    "\n",
    "invalid_inputs = []\n",
    "input_skills = set(map(str.strip, candidate_skills.split(\",\")))\n",
    "if not input_skills.issubset(valid_skills):\n",
    "    invalid_inputs.append(\"K·ªπ nƒÉng kh√¥ng t·ªìn t·∫°i trong h·ªá th·ªëng!\")\n",
    "\n",
    "if candidate_level not in valid_levels:\n",
    "    invalid_inputs.append(\"C·∫•p b·∫≠c kh√¥ng h·ª£p l·ªá!\")\n",
    "\n",
    "if candidate_location not in valid_locations:\n",
    "    invalid_inputs.append(\"V·ªã tr√≠ kh√¥ng h·ª£p l·ªá!\")\n",
    "\n",
    "if invalid_inputs:\n",
    "    print(\"‚ùå L·ªói nh·∫≠p li·ªáu:\")\n",
    "    for error in invalid_inputs:\n",
    "        print(f\" - {error}\")\n",
    "else:\n",
    "    candidate_profile = f\"I am looking for a {candidate_level} job in {candidate_location}. My key skills are {candidate_skills}.\"\n",
    "\n",
    "    # Chuy·ªÉn ƒë·ªïi th√¥ng tin ·ª©ng vi√™n th√†nh vector\n",
    "    candidate_vector = vectorizer.transform([candidate_profile])\n",
    "\n",
    "    # T√≠nh cosine similarity gi·ªØa ·ª©ng vi√™n v√† c√°c c√¥ng vi·ªác\n",
    "    similarity_scores = cosine_similarity(candidate_vector, job_vectors).flatten()\n",
    "\n",
    "    top_n = 5\n",
    "    top_jobs_indices = similarity_scores.argsort()[::-1][:top_n]\n",
    "\n",
    "    # L·∫•y danh s√°ch c√¥ng vi·ªác ph√π h·ª£p\n",
    "    top_jobs = df.iloc[top_jobs_indices][[\"job_link\", \"job_title\", \"company\", \"job_location\"]]\n",
    "\n",
    "    print(\"C√¥ng vi·ªác ƒë∆∞·ª£c g·ª£i √Ω:\")\n",
    "    print(top_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L·ªãch s·ª≠ t√¨m ki·∫øm ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o search_history.csv.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "def save_search_history(user_id, job_recommendations):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    history_data = []\n",
    "\n",
    "    for _, row in job_recommendations.iterrows():\n",
    "        history_data.append({\n",
    "            \"user_id\": user_id,\n",
    "            \"job_id\": row[\"job_link\"],\n",
    "            \"interaction_score\": 1,\n",
    "            \"timestamp\": timestamp\n",
    "        })\n",
    "\n",
    "    history_df = pd.DataFrame(history_data)\n",
    "\n",
    "    # Ghi d·ªØ li·ªáu v√†o file (append)\n",
    "    history_df.to_csv(\"search_history.csv\", mode=\"a\", index=False, header=not os.path.exists(\"search_history.csv\"))\n",
    "\n",
    "# G·ªçi h√†m l∆∞u l·ªãch s·ª≠\n",
    "save_search_history(user_id, top_jobs)\n",
    "\n",
    "print(\"L·ªãch s·ª≠ t√¨m ki·∫øm ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o search_history.csv.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
